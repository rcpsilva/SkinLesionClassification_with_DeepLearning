{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SkinLesionClassification_TransferLearningNET_pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIUgYgYYsXnR",
        "colab_type": "text"
      },
      "source": [
        "# Skin lesion classification with transfer learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGP95aMYsSKT",
        "colab_type": "text"
      },
      "source": [
        "Most of the code in this notebook was taken from https://github.com/falloutdurham/beginners-pytorch-deep-learning/. Here, it was tweaked to solve the sking lesion classification problem \n",
        "\n",
        "Please refer to the following book for more details:\n",
        "Programming PyTorch for Deep Learning by Ian Pointer - Released September 2019, Publisher(s): O'Reilly Media, Inc., ISBN: 9781492045342"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzEg1gylynMQ",
        "colab_type": "text"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKI4YjNgfSbj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "folder_path = \"/content/drive/My Drive/Skin_Lesions\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcjUvclazccd",
        "colab_type": "text"
      },
      "source": [
        "## Get data "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sO3_CWfTznw1",
        "colab_type": "text"
      },
      "source": [
        "### Image transforms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enL5-qX0zfNt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "im_size = 256\n",
        "\n",
        "img_transforms = transforms.Compose([\n",
        "    transforms.Resize((im_size,im_size)), \n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                    std=[0.229, 0.224, 0.225] )\n",
        "    ])\n",
        "\n",
        "def check_image(path):\n",
        "    try:\n",
        "        im = Image.open(path)\n",
        "        return True\n",
        "    except:\n",
        "        return False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FlNf2-FzvEY",
        "colab_type": "text"
      },
      "source": [
        "### Data loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHPKy_AFzuD_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_path = folder_path + \"/train/\"\n",
        "train_data = torchvision.datasets.ImageFolder(root=train_data_path, transform=img_transforms, is_valid_file=check_image)\n",
        "\n",
        "test_data_path = folder_path + \"/test/\"\n",
        "test_data = torchvision.datasets.ImageFolder(root=test_data_path, transform=img_transforms, is_valid_file=check_image)\n",
        "\n",
        "val_data_path = folder_path + \"/val/\"\n",
        "val_data = torchvision.datasets.ImageFolder(root=val_data_path, transform=img_transforms, is_valid_file=check_image)\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "rand_sampler_train = torch.utils.data.RandomSampler(train_data, replacement=False)\n",
        "train_data_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,sampler=rand_sampler_train)\n",
        "\n",
        "rand_sampler_val = torch.utils.data.RandomSampler(val_data,replacement=False)\n",
        "val_data_loader  = torch.utils.data.DataLoader(val_data, batch_size=batch_size,sampler=rand_sampler_val)\n",
        "\n",
        "rand_sampler_test = torch.utils.data.RandomSampler(test_data, replacement=False) \n",
        "test_data_loader  = torch.utils.data.DataLoader(test_data, batch_size=batch_size,sampler=rand_sampler_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc6_QWJpzB2P",
        "colab_type": "text"
      },
      "source": [
        "## Load pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSbGCPC2zBSh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transfer_model = models.resnet50(pretrained=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qi50CMRc0EW6",
        "colab_type": "text"
      },
      "source": [
        "## Freeze parameters\n",
        "\n",
        "Freezing everything except batch normalization layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMzpcdwyypoL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for name, param in transfer_model.named_parameters():\n",
        "    if(\"bn\" not in name):\n",
        "        param.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SCqm4fx0inB",
        "colab_type": "text"
      },
      "source": [
        "## Replacing the classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGsJQCDS0k_5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transfer_model.fc = nn.Sequential(nn.Linear(transfer_model.fc.in_features,500),\n",
        "nn.ReLU(),                                 \n",
        "nn.Dropout(), nn.Linear(500,2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdXOpEXO0yQr",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPbug8Oa04AK",
        "colab_type": "text"
      },
      "source": [
        "## Training procedure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dy_MlPu_001J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, optimizer, loss_fn, train_loader, val_loader, epochs=20, device=\"cpu\"):\n",
        "    for epoch in range(epochs):\n",
        "        training_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "        model.train()\n",
        "        for batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            inputs, targets = batch\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "            output = model(inputs)\n",
        "            loss = loss_fn(output, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            training_loss += loss.data.item() * inputs.size(0)\n",
        "        training_loss /= len(train_loader.dataset)\n",
        "        \n",
        "        model.eval()\n",
        "        num_correct = 0 \n",
        "        num_examples = 0\n",
        "        for batch in val_loader:\n",
        "            inputs, targets = batch\n",
        "            inputs = inputs.to(device)\n",
        "            output = model(inputs)\n",
        "            targets = targets.to(device)\n",
        "            loss = loss_fn(output,targets) \n",
        "            valid_loss += loss.data.item() * inputs.size(0)\n",
        "            correct = torch.eq(torch.max(F.softmax(output), dim=1)[1], targets).view(-1)\n",
        "            num_correct += torch.sum(correct).item()\n",
        "            num_examples += correct.shape[0]\n",
        "        valid_loss /= len(val_loader.dataset)\n",
        "\n",
        "        print('Epoch: {}, Training Loss: {:.2f}, Validation Loss: {:.2f}, accuracy = {:.2f}'.format(epoch, training_loss,\n",
        "        valid_loss, num_correct / num_examples))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKlq0Gth23JY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\") \n",
        "else:\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCiQMCYS2FdT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "36b822b1-bba1-4430-a2cb-dac95a5bc076"
      },
      "source": [
        "transfer_model.to(device)\n",
        "optimizer = optim.Adam(transfer_model.parameters(), lr=0.001)\n",
        "\n",
        "train(transfer_model, optimizer,torch.nn.CrossEntropyLoss(), train_data_loader,val_data_loader, epochs=20, device=device)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, Training Loss: 0.65, Validation Loss: 0.51, accuracy = 0.80\n",
            "Epoch: 1, Training Loss: 0.43, Validation Loss: 0.47, accuracy = 0.80\n",
            "Epoch: 2, Training Loss: 0.36, Validation Loss: 0.46, accuracy = 0.81\n",
            "Epoch: 3, Training Loss: 0.27, Validation Loss: 0.56, accuracy = 0.81\n",
            "Epoch: 4, Training Loss: 0.19, Validation Loss: 0.53, accuracy = 0.83\n",
            "Epoch: 5, Training Loss: 0.10, Validation Loss: 0.74, accuracy = 0.83\n",
            "Epoch: 6, Training Loss: 0.04, Validation Loss: 0.81, accuracy = 0.81\n",
            "Epoch: 7, Training Loss: 0.02, Validation Loss: 0.97, accuracy = 0.81\n",
            "Epoch: 8, Training Loss: 0.01, Validation Loss: 0.95, accuracy = 0.81\n",
            "Epoch: 9, Training Loss: 0.00, Validation Loss: 1.01, accuracy = 0.81\n",
            "Epoch: 10, Training Loss: 0.00, Validation Loss: 1.16, accuracy = 0.81\n",
            "Epoch: 11, Training Loss: 0.00, Validation Loss: 1.17, accuracy = 0.81\n",
            "Epoch: 12, Training Loss: 0.00, Validation Loss: 1.14, accuracy = 0.81\n",
            "Epoch: 13, Training Loss: 0.00, Validation Loss: 1.12, accuracy = 0.81\n",
            "Epoch: 14, Training Loss: 0.00, Validation Loss: 1.33, accuracy = 0.79\n",
            "Epoch: 15, Training Loss: 0.00, Validation Loss: 1.29, accuracy = 0.80\n",
            "Epoch: 16, Training Loss: 0.00, Validation Loss: 1.31, accuracy = 0.81\n",
            "Epoch: 17, Training Loss: 0.00, Validation Loss: 1.15, accuracy = 0.81\n",
            "Epoch: 18, Training Loss: 0.00, Validation Loss: 1.24, accuracy = 0.81\n",
            "Epoch: 19, Training Loss: 0.00, Validation Loss: 1.34, accuracy = 0.80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKtqWz1L3GPQ",
        "colab_type": "text"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ob0__WIs3Hax",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "70b88e5c-965c-413e-b707-b2e2978a448d"
      },
      "source": [
        "model = transfer_model\n",
        "num_correct = 0 \n",
        "num_examples = 0\n",
        "valid_loss = 0.0\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "mag_total = 0\n",
        "mag_right = 0\n",
        "ben_total = 0\n",
        "ben_right = 0\n",
        "\n",
        "\n",
        "for batch in test_data_loader:\n",
        "  inputs, targets = batch\n",
        "  inputs = inputs.to(device)\n",
        "  output = model(inputs)\n",
        "\n",
        "  targets = targets.to(device)\n",
        "  loss = loss_fn(output,targets) \n",
        "  valid_loss += loss.data.item() * inputs.size(0)\n",
        "\n",
        "  classes = torch.max(F.softmax(output), dim=1)[1]\n",
        "  \n",
        "  for c,t in zip(classes,targets):\n",
        "    if t == 1:\n",
        "      mag_total += 1\n",
        "      if c == 1:\n",
        "        mag_right += 1\n",
        "    else:\n",
        "      ben_total += 1\n",
        "      if c == 0:\n",
        "         ben_right += 1\n",
        "\n",
        "  correct = torch.eq(torch.max(F.softmax(output), dim=1)[1], targets).view(-1)\n",
        "  num_correct += torch.sum(correct).item()\n",
        "  num_examples += correct.shape[0]\n",
        "valid_loss /= len(test_data_loader.dataset)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcpHKAPM3iM4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "e3c40809-f7de-44f4-f7b9-abe3a3fce7c1"
      },
      "source": [
        "print('Test loss: ' + str(valid_loss) + ' Accuracy: ' + str(num_correct / num_examples))\n",
        "print('Acurracy malignant ' + str(mag_right/mag_total))\n",
        "print('Acurracy benign ' + str(ben_right/ben_total))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 1.1866410437604071 Accuracy: 0.8309859154929577\n",
            "Acurracy malignant 0.42857142857142855\n",
            "Acurracy benign 0.9298245614035088\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDw1Gl5YNOXz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}