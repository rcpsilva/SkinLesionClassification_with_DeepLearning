{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SkinLesionClassification_TransferLearningNET_pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIUgYgYYsXnR",
        "colab_type": "text"
      },
      "source": [
        "# Skin lesion classification with transfer learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGP95aMYsSKT",
        "colab_type": "text"
      },
      "source": [
        "Most of the code in this notebook was taken from https://github.com/falloutdurham/beginners-pytorch-deep-learning/. Here, it was tweaked to solve the sking lesion classification problem \n",
        "\n",
        "Please refer to the following book for more details:\n",
        "Programming PyTorch for Deep Learning by Ian Pointer - Released September 2019, Publisher(s): O'Reilly Media, Inc., ISBN: 9781492045342"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzEg1gylynMQ",
        "colab_type": "text"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKI4YjNgfSbj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "folder_path = \"/content/drive/My Drive/Skin_Lesions\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcjUvclazccd",
        "colab_type": "text"
      },
      "source": [
        "## Get data "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sO3_CWfTznw1",
        "colab_type": "text"
      },
      "source": [
        "### Image transforms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enL5-qX0zfNt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "im_size = 256\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    #transforms.RandomHorizontalFlip(p=0.5), # used for data augmentation\n",
        "    #transforms.RandomVerticalFlip(p=0.5), # used for data augmentation\n",
        "    transforms.Resize((im_size,im_size)), \n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                    std=[0.229, 0.224, 0.225] )                            \n",
        "])\n",
        "\n",
        "img_transforms = transforms.Compose([\n",
        "    transforms.Resize((im_size,im_size)), \n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                    std=[0.229, 0.224, 0.225] )\n",
        "    ])\n",
        "\n",
        "def check_image(path):\n",
        "    try:\n",
        "        im = Image.open(path)\n",
        "        return True\n",
        "    except:\n",
        "        return False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQRhKfPFC286",
        "colab_type": "text"
      },
      "source": [
        "## Class balancing sampler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0MPozknCwY9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_weights_for_balanced_classes(images, nclasses):                        \n",
        "    count = [0] * nclasses                                                      \n",
        "    for item in images:                                                         \n",
        "        count[item[1]] += 1                                                     \n",
        "    weight_per_class = [0.] * nclasses                                      \n",
        "    N = float(sum(count))                                                   \n",
        "    for i in range(nclasses):                                                   \n",
        "        weight_per_class[i] = N/float(count[i])                                 \n",
        "    weight = [0] * len(images)                                              \n",
        "    for idx, val in enumerate(images):                                          \n",
        "        weight[idx] = weight_per_class[val[1]]                                  \n",
        "    return weight "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEYjUjNdC8s7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_path = folder_path + \"/train/\"\n",
        "train_data = torchvision.datasets.ImageFolder(root=train_data_path, transform=train_transform, is_valid_file=check_image)                                                                        \n",
        "                                                                                \n",
        "# For unbalanced dataset we create a weighted sampler                       \n",
        "weights = make_weights_for_balanced_classes(train_data.imgs, len(train_data.classes))                                                                \n",
        "weights = torch.DoubleTensor(weights)                                       \n",
        "train_sampler = torch.utils.data.sampler.WeightedRandomSampler(weights, len(weights), replacement=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FlNf2-FzvEY",
        "colab_type": "text"
      },
      "source": [
        "### Data loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHPKy_AFzuD_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data_path = folder_path + \"/test/\"\n",
        "test_data = torchvision.datasets.ImageFolder(root=test_data_path, transform=img_transforms, is_valid_file=check_image)\n",
        "\n",
        "val_data_path = folder_path + \"/val/\"\n",
        "val_data = torchvision.datasets.ImageFolder(root=val_data_path, transform=img_transforms, is_valid_file=check_image)\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,sampler=train_sampler)\n",
        "val_data_loader  = torch.utils.data.DataLoader(val_data, batch_size=batch_size,shuffle=True)\n",
        "test_data_loader  = torch.utils.data.DataLoader(test_data, batch_size=batch_size,shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc6_QWJpzB2P",
        "colab_type": "text"
      },
      "source": [
        "## Load pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSbGCPC2zBSh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transfer_model = models.resnet50(pretrained=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qi50CMRc0EW6",
        "colab_type": "text"
      },
      "source": [
        "## Freeze parameters\n",
        "\n",
        "Freezing everything except batch normalization layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMzpcdwyypoL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for name, param in transfer_model.named_parameters():\n",
        "    if(\"bn\" not in name):\n",
        "        param.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SCqm4fx0inB",
        "colab_type": "text"
      },
      "source": [
        "## Replacing the classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGsJQCDS0k_5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transfer_model.fc = nn.Sequential(nn.Linear(transfer_model.fc.in_features,500),\n",
        "nn.ReLU(),                                 \n",
        "nn.Dropout(), nn.Linear(500,2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdXOpEXO0yQr",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxiVHgKt0tdP",
        "colab_type": "text"
      },
      "source": [
        "### Learning Rate Finder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1iG6xLW0sxM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_lr(model, loss_fn, optimizer, train_loader, init_value=1e-8, final_value=10.0, device=\"cpu\"):\n",
        "    number_in_epoch = len(train_loader) - 1\n",
        "    update_step = (final_value / init_value) ** (1 / number_in_epoch)\n",
        "    lr = init_value\n",
        "    optimizer.param_groups[0][\"lr\"] = lr\n",
        "    best_loss = 0.0\n",
        "    batch_num = 0\n",
        "    losses = []\n",
        "    log_lrs = []\n",
        "    for data in train_loader:\n",
        "        batch_num += 1\n",
        "        inputs, targets = data\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_fn(outputs, targets)\n",
        "\n",
        "        # Crash out if loss explodes\n",
        "\n",
        "        if batch_num > 1 and loss > 4 * best_loss:\n",
        "            if(len(log_lrs) > 20):\n",
        "                return log_lrs[10:-5], losses[10:-5]\n",
        "            else:\n",
        "                return log_lrs, losses\n",
        "\n",
        "        # Record the best loss\n",
        "\n",
        "        if loss < best_loss or batch_num == 1:\n",
        "            best_loss = loss\n",
        "\n",
        "        # Store the values\n",
        "        losses.append(loss.item())\n",
        "        log_lrs.append((lr))\n",
        "\n",
        "        # Do the backward pass and optimize\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the lr for the next step and store\n",
        "\n",
        "        lr *= update_step\n",
        "        optimizer.param_groups[0][\"lr\"] = lr\n",
        "    if(len(log_lrs) > 20):\n",
        "        return log_lrs[10:-5], losses[10:-5]\n",
        "    else:\n",
        "        return log_lrs, losses"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPbug8Oa04AK",
        "colab_type": "text"
      },
      "source": [
        "## Training procedure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dy_MlPu_001J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, optimizer, loss_fn, train_loader, val_loader, epochs=20, device=\"cpu\"):\n",
        "    for epoch in range(epochs):\n",
        "        training_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "        model.train()\n",
        "        for batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            inputs, targets = batch\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "            output = model(inputs)\n",
        "            loss = loss_fn(output, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            training_loss += loss.data.item() * inputs.size(0)\n",
        "        training_loss /= len(train_loader.dataset)\n",
        "        \n",
        "        model.eval()\n",
        "        num_correct = 0 \n",
        "        num_examples = 0\n",
        "        for batch in val_loader:\n",
        "            inputs, targets = batch\n",
        "            inputs = inputs.to(device)\n",
        "            output = model(inputs)\n",
        "            targets = targets.to(device)\n",
        "            loss = loss_fn(output,targets) \n",
        "            valid_loss += loss.data.item() * inputs.size(0)\n",
        "            correct = torch.eq(torch.max(F.softmax(output), dim=1)[1], targets).view(-1)\n",
        "            num_correct += torch.sum(correct).item()\n",
        "            num_examples += correct.shape[0]\n",
        "        valid_loss /= len(val_loader.dataset)\n",
        "\n",
        "        print('Epoch: {}, Training Loss: {:.2f}, Validation Loss: {:.2f}, accuracy = {:.2f}'.format(epoch, training_loss,\n",
        "        valid_loss, num_correct / num_examples))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKlq0Gth23JY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\") \n",
        "else:\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FE8O8GB71Fov",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transfer_model.to(device)\n",
        "optimizer = optim.Adam(transfer_model.parameters(), lr=0.001)\n",
        "\n",
        "(lrs, losses) = find_lr(transfer_model, torch.nn.CrossEntropyLoss(),optimizer, train_data_loader,device=device)\n",
        "plt.plot(lrs, losses)\n",
        "\n",
        "plt.xscale(\"log\")\n",
        "plt.xlabel(\"Learning rate\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCiQMCYS2FdT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(transfer_model.parameters(), lr=0.001)\n",
        "train(transfer_model, optimizer,torch.nn.CrossEntropyLoss(), train_data_loader,val_data_loader, epochs=15, device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKtqWz1L3GPQ",
        "colab_type": "text"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ob0__WIs3Hax",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = transfer_model\n",
        "num_correct = 0 \n",
        "num_examples = 0\n",
        "valid_loss = 0.0\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "mag_total = 0\n",
        "mag_right = 0\n",
        "ben_total = 0\n",
        "ben_right = 0\n",
        "\n",
        "\n",
        "for batch in test_data_loader:\n",
        "  inputs, targets = batch\n",
        "  inputs = inputs.to(device)\n",
        "  output = model(inputs)\n",
        "\n",
        "  targets = targets.to(device)\n",
        "  loss = loss_fn(output,targets) \n",
        "  valid_loss += loss.data.item() * inputs.size(0)\n",
        "\n",
        "  classes = torch.max(F.softmax(output), dim=1)[1]\n",
        "  \n",
        "  for c,t in zip(classes,targets):\n",
        "    if t == 1:\n",
        "      mag_total += 1\n",
        "      if c == 1:\n",
        "        mag_right += 1\n",
        "    else:\n",
        "      ben_total += 1\n",
        "      if c == 0:\n",
        "         ben_right += 1\n",
        "\n",
        "  correct = torch.eq(torch.max(F.softmax(output), dim=1)[1], targets).view(-1)\n",
        "  num_correct += torch.sum(correct).item()\n",
        "  num_examples += correct.shape[0]\n",
        "valid_loss /= len(test_data_loader.dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcpHKAPM3iM4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Test loss: ' + str(valid_loss) + ' Accuracy: ' + str(num_correct / num_examples))\n",
        "print('Acurracy malignant ' + str(mag_right/mag_total))\n",
        "print('Acurracy benign ' + str(ben_right/ben_total))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDw1Gl5YNOXz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}